{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import calendar\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"tickets.sqlite\"\n",
    "engine = create_engine(f\"sqlite:///{path}\")\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"Raw_CSV_Files\"\n",
    "month_name = {k: v.lower() for k,v in enumerate(calendar.month_name)}\n",
    "for year in range(2009,2020):\n",
    "    for month in range(1,13):\n",
    "        month = month_name[month]\n",
    "        #Check to see if the month has already been added to the database\n",
    "#         if engine.dialect.has_table(engine, \"months_added\"):\n",
    "#             month_to_add = pd.read_sql(f\"select * from months_added where Month = '{month}' and Year='{year}'\",conn)\n",
    "#             if len(month_to_add) != 0:\n",
    "#                 continue\n",
    "#         else:\n",
    "        #Create df from csv file, clean it and add it to the db\n",
    "        file_name = f\"{month.capitalize()}_{year}.csv\"\n",
    "        file_path = os.path.join(folder_name,file_name)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "        except:\n",
    "            continue\n",
    "        #Select only columns we are interested in\n",
    "        df = df[[\"OBJECTID\",\"TICKET_NUMBER\",\"ISSUE_DATE\",\"ISSUE_TIME\",\"ISSUING_AGENCY_CODE\",\"ISSUING_AGENCY_NAME\",\\\n",
    "                 \"VIOLATION_CODE\",\"VIOLATION_PROC_DESC\",\"FINE_AMOUNT\",\"LOCATION\",\"LATITUDE\",\"LONGITUDE\"]]\n",
    "        df = df.dropna(how = \"all\")\n",
    "        #Drop rows that have NaN values for columns used by the prediction model\n",
    "        df = df.dropna(subset=[\"TICKET_NUMBER\",\"ISSUE_DATE\",\"ISSUE_TIME\",\"LATITUDE\",\"LONGITUDE\"])\n",
    "        #Drop rows that don't have the right date and time format\n",
    "        time_pattern = \"\\d{2}:\\d{2} (AM|PM)\"\n",
    "        date_pattern = \"\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}.\\d{3}Z\"\n",
    "        df = df.drop(df[~df['ISSUE_TIME'].str.contains(time_pattern)].index)\n",
    "        df = df.drop(df[~df['ISSUE_DATE'].str.contains(date_pattern)].index)\n",
    "        #Change the type of the ISSUE_DATE and ISSUE_TIME column\n",
    "        df[\"ISSUE_DATE\"] = pd.to_datetime(df[\"ISSUE_DATE\"])\n",
    "        df[\"ISSUE_TIME\"] = pd.to_datetime(df[\"ISSUE_TIME\"], format=\"%I:%M %p\")\n",
    "        #Add df to database\n",
    "        df.to_sql(\"tickets\", conn, if_exists='append')\n",
    "        month_added_df = pd.DataFrame({\"Month\" : [month],\"Year\" : [year]})\n",
    "        month_added_df.to_sql(\"months_added\", conn, if_exists='append')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create smaller version\n",
    "rds_connection_string = \"user:psw@tickets2019.cpgpbvefuium.us-east-2.rds.amazonaws.com:3306/tickets2019\"\n",
    "engine = create_engine(f'mysql://{rds_connection_string}')\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql://root:root123@localhost:3306/ticketsApr19\")\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Table, Column, Integer, Float, String, DateTime, MetaData\n",
    "meta = MetaData()\n",
    "\n",
    "students = Table(\n",
    "    'tickets', meta, \n",
    "    Column(\"OBJECTID\", String(10)), \n",
    "    Column('TICKET_NUMBER', String(10), primary_key = True), \n",
    "    Column('ISSUE_DATE', DateTime),\n",
    "    Column('ISSUE_TIME', DateTime),\n",
    "    Column(\"ISSUING_AGENCY_CODE\",String(4)),\n",
    "    Column(\"ISSUING_AGENCY_NAME\",String(70)),\n",
    "    Column(\"VIOLATION_CODE\",String(7)),\n",
    "    Column(\"VIOLATION_PROC_DESC\",String(70)),\n",
    "    Column(\"FINE_AMOUNT\", Integer),\n",
    "    Column(\"LOCATION\",String(70)),\n",
    "    Column(\"LATITUDE\",Float),\n",
    "    Column(\"LONGITUDE\",Float)    \n",
    ")\n",
    "meta.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dianadumitrascu/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n"
     ]
    }
   ],
   "source": [
    "folder_name = \"Raw_CSV_Files\"\n",
    "month_name = {k: v.lower() for k,v in enumerate(calendar.month_name)}\n",
    "for year in range(2019,2020):\n",
    "    for month in range(4,5):\n",
    "        month = month_name[month]\n",
    "        #Create df from csv file, clean it and add it to the db\n",
    "        file_name = f\"{month.capitalize()}_{year}.csv\"\n",
    "        file_path = os.path.join(folder_name,file_name)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "        except:\n",
    "            continue\n",
    "        #Select only columns we are interested in\n",
    "        df = df[[\"OBJECTID\",\"TICKET_NUMBER\",\"ISSUE_DATE\",\"ISSUE_TIME\",\"ISSUING_AGENCY_CODE\",\"ISSUING_AGENCY_NAME\",\\\n",
    "                 \"VIOLATION_CODE\",\"VIOLATION_PROC_DESC\",\"FINE_AMOUNT\",\"LOCATION\",\"LATITUDE\",\"LONGITUDE\"]]\n",
    "        df = df.dropna(how = \"all\")\n",
    "        #Drop rows that have NaN values for columns used by the prediction model\n",
    "        df = df.dropna(subset=[\"TICKET_NUMBER\",\"FINE_AMOUNT\",\"ISSUE_DATE\",\"ISSUE_TIME\",\"LATITUDE\",\"LONGITUDE\"])\n",
    "        #Drop rows that have $0 for FINE_AMOUNT\n",
    "        df = df[df.FINE_AMOUNT != 0]\n",
    "        #Drop rows that don't have the right date and time format\n",
    "        time_pattern = \"\\d{2}:\\d{2} (AM|PM)\"\n",
    "        date_pattern = \"\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}.\\d{3}Z\"\n",
    "        df = df.drop(df[~df['ISSUE_TIME'].str.contains(time_pattern)].index)\n",
    "        df = df.drop(df[~df['ISSUE_DATE'].str.contains(date_pattern)].index)\n",
    "        #Change the type of the ISSUE_DATE and ISSUE_TIME column\n",
    "        df[\"ISSUE_DATE\"] = pd.to_datetime(df[\"ISSUE_DATE\"])\n",
    "        df[\"ISSUE_TIME\"] = pd.to_datetime(df[\"ISSUE_TIME\"], format=\"%I:%M %p\")\n",
    "        #Add df to database\n",
    "        #df.to_sql(\"tickets\", conn, if_exists='append')\n",
    "        df.to_sql(con=conn, name='tickets', if_exists='append', index=False)\n",
    "        month_added_df = pd.DataFrame({\"Month\" : [month],\"Year\" : [year]})\n",
    "        month_added_df.to_sql(\"months_added\", conn, if_exists='append') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_sql = pd.io.sql.pandasSQL_builder(conn, schema=None, flavor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sql_k(self, frame, name, if_exists='fail', index=True,\n",
    "           index_label=None, schema=None, chunksize=None, dtype=None, **kwargs):\n",
    "    if dtype is not None:\n",
    "        from sqlalchemy.types import to_instance, TypeEngine\n",
    "        for col, my_type in dtype.items():\n",
    "            if not isinstance(to_instance(my_type), TypeEngine):\n",
    "                raise ValueError('The type of %s is not a SQLAlchemy '\n",
    "                                 'type ' % col)\n",
    "\n",
    "    table = pd.io.sql.SQLTable(name, self, frame=frame, index=index,\n",
    "                     if_exists=if_exists, index_label=index_label,\n",
    "                     schema=schema, dtype=dtype, **kwargs)\n",
    "    table.create()\n",
    "    table.insert(chunksize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
